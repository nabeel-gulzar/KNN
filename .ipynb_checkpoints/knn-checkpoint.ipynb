{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from math import sqrt, floor\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string\n",
    "from collections import Counter\n",
    "from itertools import dropwhile\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    punctuations = string.punctuation\n",
    "    translations = text.maketrans(punctuations, ''.join([' ']*len(punctuations)))\n",
    "    return text.translate(translations)\n",
    "\n",
    "def remove_numerics(string):\n",
    "    return re.sub(r'\\d+', '', string)\n",
    "\n",
    "def remove_hashtags(string):\n",
    "    return re.sub(r'#\\w+', '', string)\n",
    "\n",
    "def remove_handles(string):\n",
    "    return re.sub(r'@\\w+', '', string)\n",
    "\n",
    "url_re = r'(http:\\/\\/)?t\\.co\\/([a-zA-Z0-9])+'\n",
    "def remove_urls(text):\n",
    "    return re.sub(url_re, '', text)\n",
    "\n",
    "def remove_stopwords(string, stopwords):\n",
    "    return ' '.join(['' if word in stopwords else word for word in string.split()])\n",
    "\n",
    "def is_stopword(word):\n",
    "    return word in stop_words\n",
    "\n",
    "def is_hashtag(word):\n",
    "    return re.match(r'#\\w+', word)\n",
    "\n",
    "def is_handle(word):\n",
    "    return re.match(r'@\\w+', word)\n",
    "\n",
    "def is_numeric(word):\n",
    "    return re.match(r'^\\d+$', word)\n",
    "\n",
    "def get_valid_word(word):\n",
    "    word = word.lower()\n",
    "    sw = is_stopword(word)\n",
    "    ht = is_hashtag(word)\n",
    "    th = is_handle(word)\n",
    "    if sw or ht or th:\n",
    "        return ''\n",
    "    word = remove_punctuations(word)\n",
    "    return '' if is_numeric(word) else word\n",
    "    \n",
    "    return word\n",
    "\n",
    "# param: tweets string[], args = {}\n",
    "def create_bow(tweets, args):\n",
    "    bow = []\n",
    "    text = ' '.join(tweets)\n",
    "    text = text.lower()\n",
    "    if len(args['stopwords']):\n",
    "        print('removing stop words...')\n",
    "        text = remove_stopwords(text, args['stopwords'])\n",
    "    if args['remove_urls']:\n",
    "        print('removing urls...')\n",
    "        text = remove_urls(text)\n",
    "    if args['remove_handles']:\n",
    "        print('removing handles...')\n",
    "        text = remove_handles(text)\n",
    "    if args['remove_hashtags']:\n",
    "        print('removing hashtags...')\n",
    "        text = remove_hashtags(text)\n",
    "    if args['remove_punctuations']:\n",
    "        print('removing punctuations...')\n",
    "        text = remove_punctuations(text)\n",
    "    if args['remove_numerics']:\n",
    "        print('removing numerics...')\n",
    "        text = remove_numerics(text)\n",
    "    text = text.split()\n",
    "    bow = Counter(text)\n",
    "    most_common = args.get('most_common', 0)\n",
    "    if args['remove_singles']:\n",
    "        for k, c in dropwhile(lambda item: item[1]>1, bow.most_common()):\n",
    "            del bow[k]\n",
    "    if most_common:\n",
    "        print('returning most common {}'.format(most_common))\n",
    "        return bow.most_common(most_common)\n",
    "    return bow\n",
    "\n",
    "def tokenize(text, args):\n",
    "    text = text.lower()\n",
    "    if len(args['stopwords']):\n",
    "        text = remove_stopwords(text, args['stopwords'])\n",
    "    if args['remove_urls']:\n",
    "        text = remove_urls(text)\n",
    "    if args['remove_handles']:\n",
    "        text = remove_handles(text)\n",
    "    if args['remove_hashtags']:\n",
    "        text = remove_hashtags(text)\n",
    "    if args['remove_punctuations']:\n",
    "        text = remove_punctuations(text)\n",
    "    if args['remove_numerics']:\n",
    "        text = remove_numerics(text)\n",
    "    words = text.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = { 'positive': 1, 'negative': -1, 'neutral': 0 }\n",
    "labels = [-1, 0, 1]\n",
    "def process_data(bow, tweets, labels, options):\n",
    "    vocab_size = len(bow)\n",
    "    sample_size = len(tweets)\n",
    "    vocab = list(bow)\n",
    "    data_x = np.zeros((sample_size, vocab_size))\n",
    "    for i, sample in enumerate(tweets):\n",
    "        for word in tokenize(sample, options):\n",
    "            try:\n",
    "                word_index = vocab.index(word)\n",
    "                data_x[i][word_index] += 1\n",
    "            except:\n",
    "                pass\n",
    "    return data_x, [Label[l] for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing stop words...\n",
      "removing urls...\n",
      "removing punctuations...\n",
      "removing numerics...\n",
      "Time taken to create BOW 2.967635154724121\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train/train.csv')\n",
    "test_df = pd.read_csv('data/test/test.csv')\n",
    "\n",
    "stopwprds = []\n",
    "with open('data/stop_words.txt', 'r') as fd:\n",
    "    stopwords = fd.read().split('\\n')\n",
    "\n",
    "bow_options = {'stopwords': stopwords,\n",
    "               'remove_urls': True,\n",
    "               'remove_handles': False,\n",
    "               'remove_hashtags': False,\n",
    "               'remove_punctuations': True,\n",
    "               'remove_numerics': True,\n",
    "               'remove_singles': False,\n",
    "              }\n",
    "\n",
    "bow = create_bow(train_df['Tweet'], bow_options)\n",
    "\n",
    "starttime = time.time()\n",
    "training_x, training_y = process_data(bow, train_df['Tweet'], train_df['Sentiment'], bow_options)\n",
    "test_x, test_y = process_data(bow, test_df['Tweet'], test_df['Sentiment'], bow_options)\n",
    "endtime = time.time()\n",
    "print('Time taken to create BOW', endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing distance matrix...(11680, 2921)\n",
      "distance matrix computed\n",
      "time taken to compute distance matrix 190.32284784317017\n"
     ]
    }
   ],
   "source": [
    "def compute_distance_matrix(training_x, test_x):\n",
    "    return distance.cdist(test_x, training_x, 'euclidean')\n",
    "\n",
    "print('computing distance matrix...({}, {})'.format(len(training_x), len(test_x)))\n",
    "starttime = time.time()\n",
    "distance_matrix = compute_distance_matrix(training_x, test_x)\n",
    "endtime = time.time()\n",
    "print('distance matrix computed')\n",
    "print('time taken to compute distance matrix', endtime - starttime)\n",
    "#time taken to compute distance matrix 271.697865486145 [with multiply sum] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting prediction...\n",
      "completed prediction\n",
      "Time taken to compute predictions 15.932597875595093\n"
     ]
    }
   ],
   "source": [
    "def partition(arr, l, r):       \n",
    "    x = arr[r] \n",
    "    i = l \n",
    "    for j in range(l, r): \n",
    "        if arr[j] <= x: \n",
    "            arr[i], arr[j] = arr[j], arr[i] \n",
    "            i += 1              \n",
    "    arr[i], arr[r] = arr[r], arr[i] \n",
    "    return i \n",
    "\n",
    "def quick_select(arr, l, r, k): \n",
    "    if (k > 0 and k <= r - l + 1): \n",
    "        index = partition(arr, l, r) \n",
    "        if (index - l == k - 1): \n",
    "            return arr[index] \n",
    "        if (index - l > k - 1): \n",
    "            return quick_select(arr, l, index - 1, k) \n",
    "        return quick_select(arr, index + 1, r, k - index + l - 1) \n",
    "    return INT_MAX\n",
    "\n",
    "def get_kth_smallest(arr, k):\n",
    "    n = len(arr) \n",
    "    return quick_select(arr, 0, n - 1, k)\n",
    "\n",
    "def get_k_nearest_indexes(distance_matrix, k):\n",
    "    temp_distance = np.array(distance_matrix)\n",
    "    kth_smallest = get_kth_smallest(temp_distance, k)\n",
    "    for i, d in enumerate(distance_matrix):\n",
    "        if d <= kth_smallest:\n",
    "            yield i\n",
    "\n",
    "def get_mod(arr):\n",
    "    label_counter = Counter(arr)\n",
    "    max_count = label_counter.most_common(1)[0][1]\n",
    "    return [k for k, c in label_counter.items() if c == max_count]\n",
    "    \n",
    "def assign_label(distance_matrix, training_labels, k):\n",
    "    k_nearest_labels = [training_labels[i] for i in get_k_nearest_indexes(distance_matrix, k)]\n",
    "    mod = get_mod(k_nearest_labels)\n",
    "    if len(mod) > 1:\n",
    "        if k == 1:\n",
    "            return mod[randint(0, len(mod) - 1)]\n",
    "        return assign_label(distance_matrix, training_labels, k-1)\n",
    "    return mod[0]\n",
    "\n",
    "def compute_accuracy(gold, predicted):\n",
    "    if len(gold) != len(predicted):\n",
    "        print('label arrays should have same size')\n",
    "        return\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range(len(gold)):\n",
    "        if gold[i] == predicted[i]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    return correct/(correct + incorrect)\n",
    "\n",
    "def compute_performance(gold, prediction):\n",
    "    accuracy = compute_accuracy(gold, prediction)\n",
    "    return accuracy\n",
    "\n",
    "def predict(distance_matrix, training_y, k):\n",
    "    test_size = distance_matrix.shape[0]\n",
    "    return [assign_label(distance_matrix[test_i], training_y, k) for test_i in range(test_size)]\n",
    "\n",
    "def generate_confusion_matrix(gold, prediction, labels):\n",
    "    if len(gold) != len(prediction):\n",
    "        print('label arrays should have same size')\n",
    "        return\n",
    "    label_count = len(labels)\n",
    "    cm = np.zeros((label_count, label_count))\n",
    "    for i in range(len(prediction)):\n",
    "        cm[labels.index(prediction[i])][labels.index(gold[i])] += 1\n",
    "    return cm\n",
    "\n",
    "print('starting prediction...')\n",
    "starttime = time.time()\n",
    "#for k in [3]:\n",
    "prediction = predict(distance_matrix, training_y, 1)\n",
    "endtime = time.time()\n",
    "print('completed prediction')\n",
    "print('Time taken to compute predictions', endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_macro_average(prediction, gold, labels):\n",
    "    if len(gold) != len(prediction):\n",
    "        print('label arrays should have same size')\n",
    "        return\n",
    "    label_count = len(labels)\n",
    "    cm = generate_confusion_matrix(test_y, prediction, labels)\n",
    "    print(cm)\n",
    "    print('-------------')\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    accuracy = 0\n",
    "    for i in range(label_count):\n",
    "        negatives = [n for n in range(label_count) if n != i]\n",
    "        tp = cm[i][i]\n",
    "        fn = np.array([cm[j][i] for j in negatives]).sum()\n",
    "        fp = np.array([cm[i][j] for j in negatives]).sum()\n",
    "        tn = np.array([np.array([cm[j][k] for j in negatives]).sum() for k in negatives]).sum()\n",
    "        print('{}\\t{}'.format(tp, fp))\n",
    "        print('{}\\t{}'.format(fn, tn))\n",
    "        print('-------({})--------'.format(labels[i]))\n",
    "\n",
    "        precision += (tp/(tp+fp))\n",
    "        recall += (tp/(tp+fn))\n",
    "        accuracy += tp\n",
    "    accuracy = accuracy/len(prediction)\n",
    "    macro_avg_precision = precision/label_count\n",
    "    macro_avg_recall = recall/label_count\n",
    "    f1_score = (2*macro_avg_precision*macro_avg_recall)/(macro_avg_precision+macro_avg_recall)\n",
    "    return {'f1': f1_score, 'precision': macro_avg_precision, 'recall': macro_avg_recall, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[862. 107.  53.]\n",
      " [719. 394. 121.]\n",
      " [253. 114. 298.]]\n",
      "-------------\n",
      "862.0\t160.0\n",
      "972.0\t927.0\n",
      "-------(-1)--------\n",
      "394.0\t840.0\n",
      "221.0\t1466.0\n",
      "-------(0)--------\n",
      "298.0\t367.0\n",
      "174.0\t2082.0\n",
      "-------(1)--------\n",
      "Accuracy: 0.5320\n",
      "F1 Score: 0.5580\n",
      "Precision: 0.5370\n",
      "Recall: 0.5807\n"
     ]
    }
   ],
   "source": [
    "macro = compute_macro_average(prediction, test_y, [-1, 0, 1])\n",
    "print('Accuracy: %.4f' % macro['accuracy'])\n",
    "print('F1 Score: %.4f' % macro['f1'])\n",
    "print('Precision: %.4f' % macro['precision'])\n",
    "print('Recall: %.4f' % macro['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10733\n"
     ]
    }
   ],
   "source": [
    "print(len(training_x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed everything\n",
    "#starting prediction...\n",
    "#Accuracy for k=1 is 0.5234508729887025\n",
    "#Accuracy for k=3 is 0.47107155083875385\n",
    "#Accuracy for k=5 is 0.4577199589181787\n",
    "#Accuracy for k=7 is 0.4471071550838754\n",
    "#Accuracy for k=10 is 0.43957548784662787\n",
    "#completed prediction\n",
    "#Time taken to compute predictions 166.01523804664612"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
